{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as T\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.utils import save_image\n",
    "from collections import OrderedDict\n",
    "import os\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.utils import save_image\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "############ Transform Functions ############\n",
    "to_img= T.Compose([T.ToPILImage()])\n",
    "to_tensor = T.Compose([T.ToTensor()])\n",
    "load_norm = T.Compose([T.ToTensor(),T.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "\n",
    "\n",
    "############ Hyper-parameters ############\n",
    "class Parser():\n",
    "    #hyperparameters\n",
    "    def __init__(self):\n",
    "        #image setting\n",
    "        self.z_dim = 62\n",
    "        self.input_size = 28\n",
    "        self.cat_dim = 10\n",
    "        self.cont_dim = 2\n",
    "        self.n_epoch = 30\n",
    "        self.batch_size = 64\n",
    "        self.lrD = 0.0002\n",
    "        self.lrG = 0.0002\n",
    "        self.b1 = 0.9\n",
    "        self.b2 = 0.999\n",
    "        self.show_freq = 50\n",
    "        self.model_path = './InfoGAN/Model/'\n",
    "        self.img_path = './InfoGAN/Image/' \n",
    "        self.img_save_freq = 500\n",
    "        self.model_save_freq = 5000\n",
    "        self.show_freq = 100\n",
    "\n",
    "args = Parser()\n",
    "\n",
    "\n",
    "\n",
    "############ Create Directories for saving imgs and models ############\n",
    "\n",
    "if not os.path.exists(args.model_path):\n",
    "    os.makedirs(args.model_path)\n",
    "if not os.path.exists(args.img_path):\n",
    "    os.makedirs(args.img_path)\n",
    "    \n",
    "    \n",
    "############ Check device ############    \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "############ Some useful layers ############\n",
    "    \n",
    "class To_sq_Image(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(To_sq_Image,self).__init__()\n",
    "    def forward(self,x):\n",
    "        return x.view(args.batch_size,-1,args.input_size//4, args.input_size//4)\n",
    "            \n",
    "class Flatten(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Flatten, self).__init__()\n",
    "    def forward(self,x):\n",
    "        return x.view(x.size(0),-1)\n",
    "    \n",
    "    \n",
    "############ Generator ############    \n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator,self).__init__()\n",
    "        self.model= nn.Sequential(OrderedDict([   # 64 is input  DCNN? \n",
    "            ('Linear_1', nn.Linear(args.z_dim+args.cat_dim+2, 1024)),\n",
    "            ('Bn_1',nn.BatchNorm1d(1024)),\n",
    "            ('L_relu_1',nn.LeakyReLU(0.2,inplace=True)),\n",
    "            ('Linear_2', nn.Linear(1024, 128*7*7)),\n",
    "            ('bn_2',nn.BatchNorm1d(128*7*7)),\n",
    "            ('L_relu_2',nn.LeakyReLU(0.2,inplace=True)),\n",
    "            ('To_Image', To_sq_Image()),\n",
    "            ('ConvT_1', nn.ConvTranspose2d(128,64,4,2,1)),\n",
    "            ('Bn_4', nn.BatchNorm2d(64)),\n",
    "            ('L_relu_4',nn.LeakyReLU(0.2,inplace=True)),\n",
    "            ('convT_2', nn.ConvTranspose2d(64,1,4,2,1)),\n",
    "            ('Tanh', nn.Tanh()),\n",
    "        ]))\n",
    "    \n",
    "    def forward(self, z, y_cont, y_cat):\n",
    "\n",
    "        y_cat_onehot = torch.zeros(args.batch_size,args.cat_dim).to(device)  \n",
    "        y_cat_onehot.scatter_(1,y_cat.unsqueeze(1),1)\n",
    "        \n",
    "        input = torch.cat([z,y_cont,y_cat_onehot],1)\n",
    "        \n",
    "        out = self.model(input)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "############ Discriminator ############\n",
    "        \n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.model = nn.Sequential(OrderedDict([\n",
    "            ('Conv_1',nn.Conv2d(1,64,4,2,1)),\n",
    "            ('L_relu_1', nn.LeakyReLU(0.2,inplace=True)),\n",
    "            ('Conv_2',nn.Conv2d(64,128,4,2,1)),\n",
    "            ('Bn_1', nn.BatchNorm2d(128)),\n",
    "            ('L_relu_2', nn.LeakyReLU(0.2,inplace=True)),\n",
    "            ('Flatten_1',Flatten()),\n",
    "            ('Linear_1',nn.Linear(6272,1024)),\n",
    "            ('Bn_2', nn.BatchNorm1d(1024)),\n",
    "            ('L_relu_3',nn.LeakyReLU(0.2)),\n",
    "        ]))\n",
    "        \n",
    "        ############ For classifying the real imgs ############\n",
    "        \n",
    "        self.classify = nn.Sequential(OrderedDict([\n",
    "            ('Linear_1',nn.Linear(1024,512)),\n",
    "            ('Bn_1',nn.BatchNorm1d(512)),\n",
    "            ('L_rela_1',nn.LeakyReLU(0.2,inplace=True)),\n",
    "            ('Linear_2',nn.Linear(512,1))\n",
    "        ]))\n",
    "\n",
    "    def forward(self,input):\n",
    "        \n",
    "        shared_tensor = self.model(input)\n",
    "        \n",
    "        target = self.classify(shared_tensor)\n",
    "      \n",
    "        return shared_tensor, target\n",
    "        \n",
    "\n",
    "class InfoGAN(nn.Module):\n",
    "    \n",
    "    def __init__(self,):\n",
    "        super(InfoGAN, self).__init__()\n",
    "        \n",
    "        \n",
    "        ############ Create Generator and Discriminator ############\n",
    "        self.G = Generator().to(device)\n",
    "        self.D = Discriminator().to(device)\n",
    "        \n",
    "        ############ Prepare Labels for Loss functions ############\n",
    "        self.y_real_, self.y_fake_ = torch.ones(args.batch_size).to(device), torch.zeros(args.batch_size).to(device)\n",
    "        \n",
    "        \n",
    "        ############ Define Q Network ############\n",
    "        \n",
    "        self.Q = nn.Sequential(OrderedDict([\n",
    "                                ('Linear_1',nn.Linear(1024,512)),\n",
    "                                ('Bn_1',nn.BatchNorm1d(512)),\n",
    "                                ('L_relu_1',nn.LeakyReLU(0.2,inplace=True)),\n",
    "                                ('Linear_2',nn.Linear(512,12)),\n",
    "                               ])).to(device)\n",
    "                                \n",
    "        ############ Define Three Loss Functions ############\n",
    "        \n",
    "        ## BCE for Classifying the real imgs\n",
    "        self.BCE_loss = nn.BCEWithLogitsLoss().to(device)\n",
    "        ## CE for Categorial C\n",
    "        self.CE_loss = nn.CrossEntropyLoss().to(device)\n",
    "        ## MSE for Continouse C\n",
    "        self.MSE_loss = nn.MSELoss().to(device)\n",
    "            \n",
    "        ############ Define Optimizers ############\n",
    "        g_params = list(self.G.parameters())+ list(self.Q.parameters())\n",
    "        self.G_optim = optim.Adam(g_params,lr = args.lrG, betas = (args.b1, args.b2))\n",
    "        \n",
    "        d_params = list(self.D.parameters())\n",
    "        self.D_optim = optim.Adam(d_params,lr = args.lrD, betas = (args.b1, args.b2))\n",
    "        \n",
    "        ############ Create Noise Distribution ############\n",
    "        self.cat_dis = torch.distributions.Categorical(torch.tensor([0.1]*args.cat_dim))\n",
    "        \n",
    "        ############ Create Loss hist ############\n",
    "        \n",
    "        self.G_loss_hist = []\n",
    "        self.D_loss_hist = []\n",
    "        self.info_loss_hist = []\n",
    "        \n",
    "    def forward(self, img):\n",
    "        \n",
    "        ###########  Train D ########### \n",
    "        \n",
    "        ########### For checking fake or true ###########\n",
    "        \n",
    "        y = self.cat_dis.sample((args.batch_size,)).to(device)\n",
    "\n",
    "        img = img.to(device)\n",
    "        \n",
    "        self.D_optim.zero_grad()\n",
    "        \n",
    "        _,D_real = self.D(img) # has been through the sigmoid function\n",
    "        D_real_loss = self.BCE_loss(D_real.squeeze(), self.y_real_)\n",
    "        self.get_noise()\n",
    "\n",
    "        self.G_img = self.G(self.z, self.y_cont, y)\n",
    "        _,D_fake = self.D(self.G_img)\n",
    "        D_fake_loss = self.BCE_loss(D_fake.squeeze(), self.y_fake_)\n",
    "\n",
    "        self.D_loss = D_real_loss + D_fake_loss\n",
    "        self.D_loss_hist.append(self.D_loss)\n",
    "        \n",
    "        self.D_loss.backward()\n",
    "        self.D_optim.step()\n",
    "        \n",
    "        ###########  Train G ########### \n",
    "        \n",
    "        self.G_optim.zero_grad()\n",
    "        self.G_img = self.G(self.z, self.y_cont, y)\n",
    "        shared_tensor, D_fake = self.D(self.G_img)\n",
    "        self.G_loss = self.BCE_loss(D_fake.squeeze(), self.y_real_)\n",
    "        self.G_loss_hist.append(self.G_loss)\n",
    "\n",
    "        ########### Info Loss ########### \n",
    "        \n",
    "        c = self.Q(shared_tensor) \n",
    "        disc_loss = self.CE_loss(c[:,args.cont_dim:], y)\n",
    "        cont_loss = self.MSE_loss(c[:,:args.cont_dim], self.y_cont)\n",
    "        self.info_loss = disc_loss + cont_loss\n",
    "        self.info_loss_hist.append(self.info_loss)\n",
    "        \n",
    "        self.G_info_loss = self.G_loss + self.info_loss\n",
    "        self.G_info_loss.backward()\n",
    "        self.G_optim.step()\n",
    "        \n",
    "    def get_noise(self,):\n",
    "\n",
    "        self.z = torch.randn(args.batch_size, args.z_dim).to(device)\n",
    "        self.y_cont = torch.FloatTensor(args.batch_size, args.cont_dim).uniform_(-1,1).to(device)\n",
    "            \n",
    "    def image_save(self, step):\n",
    "        \n",
    "        ##################### Saving Continous change imgs #####################\n",
    "        temp_c = torch.linspace(-1, 1, 8)\n",
    "        c_con_1 = torch.zeros((args.batch_size, 2))\n",
    "        for i in range(8):\n",
    "            for j in range(8):\n",
    "                c_con_1[i*8+j, 0] = temp_c[i]\n",
    "                c_con_1[i*8+j, 1] = temp_c[j]\n",
    "        \n",
    "        \n",
    "        c_con_1 = c_con_1.to(device)\n",
    "        z_1= torch.rand((1, args.z_dim)).expand(args.batch_size, args.z_dim).to(device)\n",
    "        c_cat_1 = torch.ones(args.batch_size).type(torch.LongTensor).to(device)\n",
    "            \n",
    "        change_cont = self.G(z_1,c_con_1,c_cat_1)   \n",
    "        \n",
    "        save_image(change_cont, args.img_path+'Con_Grids_S_'+str(step)+'.png',\n",
    "                   nrow=8, normalize=True,range=(-1,1))\n",
    "        \n",
    "        ##################### Saving Categorail change imgs #####################\n",
    "        \n",
    "        sample_z = []\n",
    "        for i in range(8):\n",
    "            sample_z.append(torch.rand(1,args.z_dim).repeat(8,1))\n",
    "\n",
    "        z_2 = torch.stack(sample_z).view(-1,args.z_dim).to(device)\n",
    "        con_c = torch.zeros(args.batch_size,2).to(device)\n",
    "        cat_c = torch.arange(args.cat_dim).repeat(7).type(torch.LongTensor)[:args.batch_size].to(device)\n",
    "  \n",
    "        change_cat = self.G(z_2,con_c,cat_c)\n",
    "        save_image(change_cont[:60], args.img_path+'Cat_Grids_S_'+str(step)+'.png',\n",
    "                   nrow=args.cat_dim, normalize=True,range=(-1,1))\n",
    "        \n",
    "        \n",
    "        ##################### Saving Training imgs ##################### \n",
    "        \n",
    "        training_img_path = args.img_path + \"InfoGAN_Step_\"+str(step)+\".png\"\n",
    "        save_image(self.G_img[:25], training_img_path , nrow=5, normalize=True, range=(-1,1))\n",
    "        print('Image saved')\n",
    "        \n",
    "    def model_save(self,step):\n",
    "        \n",
    "        path = args.model_path + 'InfoGAN_Step_' + str(step) + '.pth'\n",
    "        torch.save({'InfoGAN':self.state_dict()}, path)\n",
    "        print('Model saved')\n",
    "    \n",
    "    def load_step_dict(self, step):\n",
    "        \n",
    "        path = args.model_path + 'InfoGAN_Step_' + str(step) + '.pth'\n",
    "        self.load_state_dict(torch.load(path, map_location=lambda storage, loc: storage)['InfoGAN'])\n",
    "        \n",
    "    def plot_all_loss(self,):\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize= (20,20))\n",
    "        plt.subplot(212)\n",
    "        plt.plot(self.G_loss_hist,label='G_loss')\n",
    "        plt.plot(self.D_loss_hist,label='D_loss')\n",
    "        plt.plot(self.info_loss_hist,label='Info_loss')\n",
    "        plt.ylabel('Loss',fontsize=15)\n",
    "        plt.xlabel('Number of Steps',fontsize=15)\n",
    "        plt.title('Loss',fontsize=30,fontweight =\"bold\")\n",
    "        plt.legend(loc = 'upper left')\n",
    "        fig.savefig(\"InfoGAN_Loss.png\")\n",
    "        \n",
    "    def num_all_params(self,):\n",
    "        \n",
    "        return sum([param.nelement() for param in infoGAN.parameters()])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(datasets.MNIST('./data/mnist',train=True,\n",
    "                    download=True,transform=load_norm),\n",
    "                    batch_size=args.batch_size, shuffle=True,drop_last=True) \n",
    "\n",
    "\n",
    "infoGAN = InfoGAN().to(device)\n",
    "\n",
    "epoch = 0\n",
    "all_steps = 1\n",
    "\n",
    "############## Strat Training ##############\n",
    "\n",
    "while epoch < args.n_epoch:\n",
    "    \n",
    "    for i,(img,y) in enumerate(dataloader):\n",
    "\n",
    "        start_t = time.time()\n",
    "        infoGAN(img)\n",
    "        end_t = time.time()\n",
    "        \n",
    "        print('| Epoch [%d] | batch [%d] | D Loss: [%.4f] | G Loss: [%.4f] | Info Loss: [%.4f] | Time: %.1fs' %\\\n",
    "              (epoch, i, infoGAN.D_loss.item(), infoGAN.G_loss.item(), infoGAN.info_loss.item(),\n",
    "               end_t - start_t))\n",
    "        \n",
    "        all_steps += 1\n",
    "        #args.show_freq \n",
    "        if all_steps % args.show_freq == 0:  \n",
    "            plt.figure()\n",
    "            plt.imshow(to_img(infoGAN.G_img[0].cpu()))\n",
    "            plt.show()\n",
    "            if all_steps % args.img_save_freq == 0: \n",
    "                infoGAN.image_save(all_steps)\n",
    "                if all_steps % args.model_save_freq == 0:\n",
    "                    infoGAN.model_save(all_steps)\n",
    "                    \n",
    "    epoch += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
